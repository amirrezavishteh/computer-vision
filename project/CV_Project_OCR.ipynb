{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import *\n",
        "from skimage.metrics import structural_similarity as ssim"
      ],
      "metadata": {
        "id": "fJK3hGv2RLnQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/keras-ocr/"
      ],
      "metadata": {
        "id": "13p7ZrNzaQzd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/faustomorales/keras-ocr.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uQstCD7aPJb",
        "outputId": "eaf47311-e557-406c-d14a-13172a0c0dc3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'keras-ocr'...\n",
            "remote: Enumerating objects: 1044, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 1044 (delta 11), reused 20 (delta 7), pack-reused 1010\u001b[K\n",
            "Receiving objects: 100% (1044/1044), 1.06 MiB | 8.31 MiB/s, done.\n",
            "Resolving deltas: 100% (657/657), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elc_ryVlzMDN",
        "outputId": "74d43a2b-17df-4a98-ffaa-4a598fe97d33"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet"
      ],
      "metadata": {
        "id": "bvaLAPRmbVhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install validators"
      ],
      "metadata": {
        "id": "HvabHiq5bk8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(im):\n",
        "    width, height, *channels = im.shape\n",
        "    plt.figure(figsize=(10,10))\n",
        "    if channels:\n",
        "        # By default, OpenCV tends to work with images in the BGR format.\n",
        "        # This is due to some outdated practices, but it has been left in the library.\n",
        "        # We can iterate the channels in reverse order to get an RGB image.\n",
        "        plt.imshow(im[:,:,::-1])\n",
        "    else:\n",
        "        plt.imshow(im, cmap='gray')\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "Kq5aIVN2eBfi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(image_path):\n",
        "  im = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
        "  im_rgb = cv2.imread(image_path)\n",
        "  edited= cv2.GaussianBlur(im,(1,1),3)\n",
        "  # plt.imshow(edited, cmap='gray')\n",
        "  # plt.show()\n",
        "\n",
        "  th3 = cv2.adaptiveThreshold(edited ,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,1001,0)\n",
        "  edgeimage= cv2.Canny(th3,30,50)\n",
        "  # plt.imshow(edgeimage,cmap=\"gray\")\n",
        "  # plt.show()\n",
        "  contours,_=cv2.findContours(edgeimage,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "  max_con = contours[0]\n",
        "  max_con_A = len(max_con)\n",
        "  for cnt in contours:\n",
        "      if len(cnt) > max_con_A:\n",
        "          max_con_A = len(cnt)\n",
        "          max_con = cnt\n",
        "  res = im_rgb.copy()\n",
        "  epsilon = 0.01 * cv2.arcLength(\n",
        "                              max_con, True)\n",
        "  approx = cv2.approxPolyDP(max_con, epsilon, True)\n",
        "\n",
        "  pts1 = np.float32([approx[0], approx[1], approx[2], approx[3]])\n",
        "  width, height = im.shape[0], im.shape[1]\n",
        "  pts2 = np.float32([[width, 0], [0, 0], [0, height], [width, height]])\n",
        "  M = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "  output_img = cv2.warpPerspective(res, M, (width, height))\n",
        "  return output_img"
      ],
      "metadata": {
        "id": "z608JkX9kxBJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maching(img, template):\n",
        "\n",
        "    mach = 0\n",
        "\n",
        "    rotate_image=[]\n",
        "    rotate_image.append(img)\n",
        "    rotate_image.append(  cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE))\n",
        "    rotate_image.append(   cv2.rotate(img, cv2.ROTATE_180))\n",
        "    rotate_image.append(   cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
        "    for rotated in rotate_image:\n",
        "\n",
        "\n",
        "        # Perform template matching\n",
        "        temp = cv2.resize(template, (136, 123))\n",
        "        image = cv2.resize(rotated, (1280, 827))\n",
        "        result = cv2.matchTemplate(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY), cv2.TM_CCOEFF_NORMED)\n",
        "\n",
        "        if np.max(result) > 0.65:\n",
        "            mach = 1\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    if mach == 1:\n",
        "        return True\n",
        "\n",
        "    # Perform template matching with flipped template\n",
        "    result_flipped = cv2.matchTemplate(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), cv2.cvtColor(template, cv2.COLOR_BGR2GRAY), cv2.TM_CCOEFF_NORMED)\n",
        "    if np.max(result_flipped) > 0.65:\n",
        "        return True\n",
        "\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "3oNNYdFhk_2x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_points_of_rectangle(potentials, rects): # potentials items : (content, index, area)\n",
        "  most_left_top = sorted(potentials, key= lambda x: rects[x[1]][1][0][0])[0]\n",
        "  most_right_bottom = sorted(potentials, key= lambda x: rects[x[1]][1][2][0])[-1]\n",
        "  return rects[most_left_top[1]][1][0], rects[most_right_bottom[1]][1][2]"
      ],
      "metadata": {
        "id": "Vyz7HLvMsCVs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_number(potentials, rects):\n",
        "  nums = sorted(potentials, key= lambda x: rects[x[1]][1][0][0])\n",
        "  return nums[0][0]+nums[1][0]+nums[2][0]+nums[3][0]"
      ],
      "metadata": {
        "id": "7wk40B5la0IS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_info(images, prediction_groups, is_identity):\n",
        "  info = []\n",
        "  for i in range(len(prediction_groups)):\n",
        "    if is_identity[i]:\n",
        "      info.append(\"it is a identity card\")\n",
        "      continue\n",
        "    im = images[i]\n",
        "    potentials = []\n",
        "    for ind,pred in enumerate(prediction_groups[i]):\n",
        "      top_left,top_right,bottom_right,bottom_left = (pred[1][0],pred[1][1],pred[1][2],pred[1][3])\n",
        "      wid = (top_left[0]-top_right[0])**2 + (top_left[1]-top_right[1])**2\n",
        "      height = (bottom_left[0]-bottom_right[0])**2 + (bottom_left[1]-bottom_right[1])**2\n",
        "      area = wid*height\n",
        "      if pred[0].isdigit() and len(pred[0])==4:\n",
        "        potentials.append((pred[0],ind,area))\n",
        "    potentials = sorted(potentials, key=lambda x: x[2], reverse=True)\n",
        "    card_number_parts = potentials[:4]\n",
        "    card_num = find_number(card_number_parts, prediction_groups[i])\n",
        "    pt1,pt2 = get_points_of_rectangle(card_number_parts, prediction_groups[i])\n",
        "    s,t = (int(pt1[0]),int(pt1[1])), (int(pt2[0]),int(pt2[1]))\n",
        "    info.append((card_num, s, t))\n",
        "  return info"
      ],
      "metadata": {
        "id": "YEbT8iJ2S6t8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "from google.colab.patches import cv2_imshow\n",
        "# keras-ocr will automatically download pretrained\n",
        "# weights for the detector and recognizer.\n",
        "def predict(images):\n",
        "  if os.path.exists(\"images\"):\n",
        "    shutil.rmtree(\"images\")\n",
        "\n",
        "  # Create new images directory\n",
        "  os.makedirs(\"images\")\n",
        "  template = cv2.imread(\"/content/iran2.jpg\")\n",
        "  is_identity = [False]*len(images)\n",
        "  pre_images = []\n",
        "  for i,im in enumerate(images):\n",
        "    preprocessed_img = preprocessing(im)\n",
        "    # Save output image\n",
        "    output_path = os.path.join(\"images\", f\"{i}_processed.jpg\")\n",
        "    cv2.imwrite(output_path, preprocessed_img)\n",
        "    pre_im = cv2.imread(f\"/content/images/{i}_processed.jpg\")\n",
        "    pre_images.append(pre_im)\n",
        "    is_identity[i] = maching(pre_im, template)\n",
        "\n",
        "  %cd keras-ocr/keras_ocr/\n",
        "  import pipeline, tools\n",
        "  pipeline = pipeline.Pipeline()\n",
        "  # Get a set of three example images\n",
        "  urls = []\n",
        "  for u in range(len(images)):\n",
        "    urls.append(f\"/content/images/{u}_processed.jpg\")\n",
        "  images = [\n",
        "      tools.read(url) for url in urls\n",
        "  ]\n",
        "\n",
        "  # Each list of predictions in prediction_groups is a list of\n",
        "  # (word, box) tuples.\n",
        "  prediction_groups = pipeline.recognize(images)\n",
        "  fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
        "  for ax, image, predictions in zip(axs, images, prediction_groups):\n",
        "    tools.drawAnnotations(image=image, predictions=predictions, ax=ax)\n",
        "  info = detect_info(images, prediction_groups, is_identity)\n",
        "  for i in range(len(images)):\n",
        "    if isinstance(info[i], str):\n",
        "      print(info[i])\n",
        "      cv2_imshow(images[i])\n",
        "    else:\n",
        "      print(info[i][0])\n",
        "      im = cv2.rectangle(im, info[i][1], info[i][2], (0, 0, 255), 2)\n",
        "      cv2_imshow(im)\n",
        "\n",
        "  # Plot the predictions\n"
      ],
      "metadata": {
        "id": "vF2jFyIWpCTl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict([\"/content/3.jpg\",\"/content/8.jpg\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnRzTacbswuZ",
        "outputId": "c09754bd-ce86-49c2-bbb2-2634938b9d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keras-ocr/keras_ocr\n",
            "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Looking for /root/.keras-ocr/crnn_kurapan.h5\n"
          ]
        }
      ]
    }
  ]
}